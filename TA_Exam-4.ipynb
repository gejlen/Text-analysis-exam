{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TA_Exam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxhXVR87j9io",
        "colab_type": "text"
      },
      "source": [
        "Importing dataset and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeLU_praCDES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4a7dc01d-01ca-43eb-dd87-cf67850fe254"
      },
      "source": [
        "#Library import/download\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from textblob import TextBlob\n",
        "import pickle\n",
        "from urllib.parse import urlparse\n",
        "import requests\n",
        "from urllib.request import urlopen, urlretrieve\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9zw-paVjj2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "f1072e5c-f34e-4af0-db60-2658d3ebdfe6"
      },
      "source": [
        "#Mounting google drive(Will only function if the file is shared with your google account)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#data import\n",
        "df = pd.read_csv(\"drive/My Drive/movie_data.csv\")\n",
        "#Inspecting the first ten lines we can conclude that zero is negative and 1 is positive\n",
        "df.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie is just crap. Even though the direc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Another detailed work on the subject by Dr Dwi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE CAT O'NINE TAILS (Il Gatto a Nove Code) &lt;b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Like with any movie genre, there are good gang...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I watched it with my mom and we were like...&lt;b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This movie is probably one of 3 worst movies m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>this movie is quite bad, aggressive, not playe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>And a perfect film to watch during the holiday...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I like Noel Coward, the wit. I like Noel Cowar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"The Days\" is a typical family drama with a li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  This movie is just crap. Even though the direc...          0\n",
              "1  Another detailed work on the subject by Dr Dwi...          1\n",
              "2  THE CAT O'NINE TAILS (Il Gatto a Nove Code) <b...          0\n",
              "3  Like with any movie genre, there are good gang...          0\n",
              "4  I watched it with my mom and we were like...<b...          0\n",
              "5  This movie is probably one of 3 worst movies m...          0\n",
              "6  this movie is quite bad, aggressive, not playe...          0\n",
              "7  And a perfect film to watch during the holiday...          1\n",
              "8  I like Noel Coward, the wit. I like Noel Cowar...          0\n",
              "9  \"The Days\" is a typical family drama with a li...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDL_4YS3kLLk",
        "colab_type": "text"
      },
      "source": [
        "Functions: Model performance and data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvbiZ1LWNEPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for model performance(Confusion matrix and classification)\n",
        "def model_performance(X_train: np.ndarray, y_train: np.ndarray,\n",
        "                      X_test: np.ndarray, y_test: np.ndarray, model):\n",
        "    model.fit(X_train, y_train) \n",
        "    predicted = model.predict(X_test)\n",
        "    try:\n",
        "        probs = model.predict_proba(X_test)\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    print('\\nClassification Report:')\n",
        "    print(classification_report(y_test, predicted))\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(confusion_matrix(y_test, predicted))\n",
        "\n",
        "porter = PorterStemmer()\n",
        "#Preprocessor model. Applied to all data to make words with the same meaning \n",
        "#being spelled the same way and all in lower.\n",
        "def preprocessor(text):\n",
        "  text =re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "  return[porter.stem(word) for word in text.split()]\n",
        "\n",
        "\n",
        "#Just an empty function as we could not make the tfdidf work with no \n",
        "#tokenizer input, but the data is already tokenized with the preprocessor\n",
        "def fill(text):\n",
        "  return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPDVrK9mahUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "858dd6f3-421d-44e7-b290-72fc5d925bd1"
      },
      "source": [
        "df['review'] = df['review'].apply(preprocessor)\n",
        "#print(df['review'])\n",
        "\n",
        "\n",
        "#Vectorization:\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None, tokenizer=fill, use_idf=True, norm='l2', smooth_idf=True)\n",
        "y = df.sentiment.values\n",
        "X = tfidf.fit_transform(df.review)\n",
        "\n",
        "#Splitting into test and train sets:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3, shuffle=False)\n",
        "clf = LogisticRegressionCV(cv=5, scoring=\"accuracy\", random_state=1, n_jobs=-1, verbose=3,max_iter=300).fit(X_train, y_train)\n",
        "\n",
        "#Running the clf.predict functions which is the function that predict the sentiment of the review\n",
        "yhat = clf.predict(X_test)\n",
        "\n",
        "#Printing clf score(Accuracy) and running the model performance function to get a better insight into the result.\n",
        "print(\"accuracy:\")\n",
        "print(clf.score(X_test, y_test))\n",
        "\n",
        "model_performance(X_train, y_train, X_test, y_test, clf)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy:\n",
            "0.8993396037622573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      7512\n",
            "           1       0.89      0.91      0.90      7479\n",
            "\n",
            "    accuracy                           0.90     14991\n",
            "   macro avg       0.90      0.90      0.90     14991\n",
            "weighted avg       0.90      0.90      0.90     14991\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6685  827]\n",
            " [ 682 6797]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMWDtIWW6OtS",
        "colab_type": "text"
      },
      "source": [
        "**Webscraped data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl8ptq7wrTSP",
        "colab_type": "text"
      },
      "source": [
        "We use the same data as in the first model, combined with new data we scrape from imdb and try to predict the sentiment of the new data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxzMrYvHxvEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The movie \"Joker\" IMBD review page\n",
        "url_link='https://www.imdb.com/title/tt7286456/reviews'\n",
        "html=urlopen(url_link)\n",
        "\n",
        "#Transforming the page into to beutifulsoup\n",
        "content_bs=BeautifulSoup(html)\n",
        "\n",
        "#Empty list to append the reviews to\n",
        "JokerReviews = []\n",
        "\n",
        "#All the reviews ends in a div class called text in html, can be found in the imdb source code\n",
        "for b in content_bs.find_all('div',class_='text'):\n",
        "  JokerReviews.append(b)\n",
        "\n",
        "df2 = pd.DataFrame.from_records(JokerReviews)\n",
        "jokerdata2 = pd.DataFrame(df2[0])\n",
        "#Adding sentimen column in order to be able to append this data directly to \n",
        "#the original dataset\n",
        "jokerdata2['sentiment'] = \"0\"\n",
        "jokerdata2['dataset'] = \"Webscraped\"\n",
        "#Renameing the 0 column to review, again in order to be able to append the data\n",
        "#directly to the original dataset.\n",
        "jokerdata2.rename(columns={\"0\": \"review\"})\n",
        "#Loading the original dataset\n",
        "df3 = pd.read_csv(\"drive/My Drive/movie_data.csv\")\n",
        "df3['dataset'] = \"Original\"\n",
        "jokerdata2.rename(columns={0:'review'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giaY62iA6Mw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "9dd56cca-5ab8-4ee7-fe74-11840a19d461"
      },
      "source": [
        "#Checking that we have matching columns\n",
        "print(jokerdata2.columns)\n",
        "print(df3.columns)\n",
        "\n",
        "#Checking that we get the expected shape\n",
        "totalstack = jokerdata2.append(df3)\n",
        "print(totalstack.shape)\n",
        "print(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['review', 'sentiment', 'dataset'], dtype='object')\n",
            "Index(['review', 'sentiment', 'dataset'], dtype='object')\n",
            "(49994, 3)\n",
            "                                                    0  ...                  24\n",
            "0   I was a person that saw all the hype and claim...  ...                None\n",
            "1   Every once in a while a movie comes, that trul...  ...                None\n",
            "2   This is a movie that only those who have felt ...  ...                None\n",
            "3   Truly a masterpiece, The Best Hollywood film o...  ...                None\n",
            "4   Joaquin Phoenix gives a tour de force performa...  ...                None\n",
            "5   Most of the time movies are anticipated like t...  ...                None\n",
            "6   Let me start off by saying if Joaquin Phoneix ...  ...                None\n",
            "7   I get why some people hate this . It's because...  ...                None\n",
            "8   I have seen Joker yesterday at Venice an early...  ...                None\n",
            "9   It's sad that Joaquin missed Oscar for 'The gl...  ...                None\n",
            "10  I have just watched the Joker in Venice and I ...  ...                None\n",
            "11  There is no doubt that the movie was well thou...  ...                None\n",
            "12  This movie causes the audience to consider man...  ...                None\n",
            "13  The acting, cinematography, sound design, and ...  ...                None\n",
            "14  The movie affects you in a way that makes it p...  ...                None\n",
            "15  Need I say more? Everything about this Movie i...  ...                None\n",
            "16  I will stop watching movies if Joaquin Phoenix...  ...                None\n",
            "17  I quit relying on critic reviews years ago... ...  ...                None\n",
            "18  Joaquin Phoenix IS the joker. Phoenix gave a p...  ...                None\n",
            "19  I thought this film was good but I just don't ...  ...                None\n",
            "20  I went into this film expecting an all-time cl...  ...                None\n",
            "21  Joker is directed by Todd Philips and stars Jo...  ...  Final Grade - 9/10\n",
            "22  Do not really understand all the tens here. Su...  ...                None\n",
            "23  When I heard everyone saying that this is the ...  ...                None\n",
            "24  Joaquin Phoenix gives Heath Ledger a run for h...  ...                None\n",
            "\n",
            "[25 rows x 25 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5uzrt1XEiBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#applying preprocessing\n",
        "totalstack['review'] = totalstack['review'].apply(preprocessor)\n",
        "print(totalstack['review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFKo2o2HE-SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorization of the entire data\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None, tokenizer=fill, use_idf=True, norm='l2', smooth_idf=True)\n",
        "y = totalstack.sentiment.values\n",
        "X = tfidf.fit_transform(totalstack.review)\n",
        "\n",
        "#Getting the  length of the webscraped data.\n",
        "n = len(df2)\n",
        "\n",
        "#Using n to sort out the webscraped data, and storing it as test data.\n",
        "#Rest in training\n",
        "test_y = y[:n] \n",
        "test_X = X[:n]\n",
        "train_y=y[n:]\n",
        "train_X=X[n:]\n",
        "#Chaning types to int\n",
        "train_y=train_y.astype('int')\n",
        "test_y=test_y.astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6G-GRAtLn4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dc6d6523-a5ab-40c5-fad6-91c5e831c640"
      },
      "source": [
        "clf = LogisticRegressionCV(cv=5, scoring=\"accuracy\", random_state=1, n_jobs=-1, verbose=3,max_iter=300).fit(train_X, train_y)\n",
        "yhat = clf.predict(test_X)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}